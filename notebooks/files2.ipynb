{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d356a3fd",
   "metadata": {},
   "source": [
    "# configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636bcfe4",
   "metadata": {},
   "source": [
    "## rtst.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e120fc9",
   "metadata": {},
   "source": [
    "``` yaml\n",
    "device: auto   # 可选值：auto、cuda、cpu\n",
    "experiment: 4 # 训练实验号，影响部分文件名字，比如日志文件，Tensorboard文件\n",
    "load: 3 # 加载权重标号，前面是RTST_，下一个是保存的标号\n",
    "save: 3\n",
    "a: 1 #1 # 三种损失的比例\n",
    "b: 100000 #1e5\n",
    "c: 1e-7 #5e-6\n",
    "style_pic: 'data/impression.jpg' # 风格图片路径\n",
    "content_layers: ['15']               # relu3_3\n",
    "style_layers: ['3', '8', '15', '22']  # relu1_2, relu2_2, relu3_3, relu4_3\n",
    "weights_path: 'weights/' # 权重文件夹\n",
    "mean: [0.485, 0.456, 0.406] # imagenet常用数值\n",
    "std: [0.229, 0.224, 0.225]\n",
    "pic_size: 256 # 输入图片裁切尺寸\n",
    "\n",
    "lr: 1e-3            # 学习率  \n",
    "epochs: 20          # 迭代次数  \n",
    "batch_size: 16\n",
    "freq: 50 # 多少步打印一个Batchsize的图片\n",
    "train_subset_len: 20000       # 划分数据集子集大小              \n",
    "val_subset_len: 1000                    \n",
    "mode: 'train' # 模式，test是使用data下的test文件夹中的一个图片，对一个图片做过拟合尝试，还有一些参数都会在src/utils/cfg.py中自动做修改；train是子集下训练；full_train是在完整数据集下训练\n",
    "\n",
    "cv_mode: 'video' # video是处理视频模式，调用visualize.py；camera是使用摄像头，但是wsl不支持\n",
    "video_path: 'data/video/hfut.mp4' # 原视频路径\n",
    "output_path: 'results/video/output_2.mp4' # 输出视频路径\n",
    "weight_path: 'weights/rtst_4.pth' # 加载权重文件的路径\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392b5afd",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5aea07",
   "metadata": {},
   "source": [
    "train放置训练集数据，test中放置一张图片做简单测试，val放置验证集数据，其他图片是风格图片"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b12f66",
   "metadata": {},
   "source": [
    "## StyleDataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044804c0",
   "metadata": {},
   "source": [
    "根据参数文件中的值设定不同的数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a025f7",
   "metadata": {},
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aff0e1",
   "metadata": {},
   "source": [
    "## rtst.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462d82f9",
   "metadata": {},
   "source": [
    "架构是直接对图片处理，不将一份图片残差传到最终输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e378ff9f",
   "metadata": {},
   "source": [
    "## results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d7ea74",
   "metadata": {},
   "source": [
    "store中放置训练过程中可视化出来的中间结果。video放置实时处理视频的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8088d9",
   "metadata": {},
   "source": [
    "# src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fca3f2",
   "metadata": {},
   "source": [
    "## fe_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a80c1a7",
   "metadata": {},
   "source": [
    "提取图片特征模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2ed8a9",
   "metadata": {},
   "source": [
    "## test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2523ed",
   "metadata": {},
   "source": [
    "测试wsl中OpenCV的使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de05afe1",
   "metadata": {},
   "source": [
    "## visualize.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c6ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from models.rtst import TransformerNet\n",
    "from src.utils.cfg import cfg, transform_pic, transform_pics\n",
    "\n",
    "cv_mode = cfg['cv_mode']\n",
    "mean = cfg['mean']\n",
    "std = cfg['mean']\n",
    "\n",
    "\n",
    "# 初始化参数设备和模型\n",
    "device = cfg['device']\n",
    "video_path = cfg['video_path']\n",
    "weight_path = cfg['weight_path']\n",
    "output_path = cfg['output_path']\n",
    "\n",
    "print(device)\n",
    "model = TransformerNet().to(device).eval()\n",
    "checkpoint = torch.load(weight_path, map_location=device, weights_only=True)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# 后处理：(-1,1)->(0,1) 并转回 NumPy\n",
    "def postprocess(tensor):\n",
    "    img = (tensor + 1) / 2\n",
    "    img = img.clamp(0, 1)\n",
    "    img = img.permute(1, 2, 0).cpu().numpy()  # H×W×C\n",
    "    return (img * 255).astype(np.uint8)\n",
    "\n",
    "# 打开视频文件\n",
    "\n",
    "if cv_mode == 'video':\n",
    "    # 处理视频\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 25\n",
    "    \n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')        # mp4v/mjpg/xvid\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))\n",
    "\n",
    "    delay = int(1000 / fps)\n",
    "elif cv_mode == 'camera':\n",
    "    # 使用摄像头\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    delay = 1\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 预处理：BGR->RGB->PIL->Tensor\n",
    "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil = Image.fromarray(img_rgb)\n",
    "    input_tensor = transform_pics(pil).unsqueeze(0).to(device)\n",
    "\n",
    "    # 模型推理\n",
    "    with torch.no_grad():\n",
    "        output_tensor = model(input_tensor)[0]\n",
    "\n",
    "    # 后处理 + 转回 BGR\n",
    "    out_img = postprocess(output_tensor)\n",
    "    out_bgr = cv2.cvtColor(out_img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    out.write(out_bgr)\n",
    "\n",
    "    # 显示与退出判断\n",
    "    cv2.imshow(\"Stylized\", out_bgr)\n",
    "    key = cv2.waitKey(delay=delay)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c2ea5",
   "metadata": {},
   "source": [
    "opencv做的就是读取视频文件然后一帧帧获取图片，传给模型然后显示和保存，中间需要定义一下对象以及对图片数据进行处理，转化。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
