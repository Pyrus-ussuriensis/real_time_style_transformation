{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20dea5ee",
   "metadata": {},
   "source": [
    "# .vscode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6f75f9",
   "metadata": {},
   "source": [
    "## launch.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37304457",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "    \"version\": \"0.2.0\",\n",
    "    \"configurations\": [\n",
    "        {\n",
    "            \"name\": \"Python: Current File (WSL)\",\n",
    "            \"type\": \"debugpy\",\n",
    "            \"request\": \"launch\",\n",
    "            \"program\": \"${file}\",\n",
    "            \"console\": \"integratedTerminal\",\n",
    "            \"cwd\": \"${workspaceFolder}\",    // 这里会自动使用当前工作区的根目录\n",
    "            \"env\": { \"PYTHONPATH\": \"${workspaceFolder}\" }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1687012a",
   "metadata": {},
   "source": [
    "## setting.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb0b1d",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "    \"python.pythonPath\": \"/root/miniconda/envs/cv/bin/python\",\n",
    "    \"python.analysis.extraPaths\": [\n",
    "    \"${workspaceFolder}\",\n",
    "    \"${workspaceFolder}/src\"\n",
    "    ]\n",
    "    \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d74cb",
   "metadata": {},
   "source": [
    "这里的两个，第一个只会影响调试的时候，第二个只会影响我们写代码的时候的提示。所以这两个都无法使运行时能识别到根目录，我们需要再.zshrc中这样设置\n",
    "```bash\n",
    "export PYTHONPATH=\"$PYTHONPATH:/mnt/d/Projects/real_time_style_transformation\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92adf593",
   "metadata": {},
   "source": [
    "# configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33d8206",
   "metadata": {},
   "source": [
    "## rtst.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29923af1",
   "metadata": {},
   "source": [
    "```yaml\n",
    "device: auto   # 可选值：auto、cuda、cpu\n",
    "experiment: 0\n",
    "batch_size: 16\n",
    "lr: 1e-2            # 学习率  \n",
    "epochs: 50          # 迭代次数 \n",
    "a: 1 # 三种损失的比例\n",
    "b: 1e-5\n",
    "c: 1e-6\n",
    "style_pic: 'data/starrynight.jpg'\n",
    "content_layers: ['21']\n",
    "style_layers: ['0', '5', '10', '19', '28']\n",
    "weights_path: 'weights/'\n",
    "mean: [0.485, 0.456, 0.406]\n",
    "std: [0.229, 0.224, 0.225]\n",
    "pic_size: 256\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d07e7d",
   "metadata": {},
   "source": [
    "这个配置要通过后面的src.utils.cfg来处理读取，处理后内容就是一个字典，然后如果是数字读取后需要转化后使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36413e4c",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa324c33",
   "metadata": {},
   "source": [
    "## StyleDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc9ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import glob\n",
    "from src.utils.cfg import cfg\n",
    "\n",
    "mean = cfg['mean']\n",
    "std = cfg['std']\n",
    "batch_size = cfg['batch_size']\n",
    "pic_size = int(cfg['pic_size'])\n",
    "\n",
    "class StyleDataset(Dataset):\n",
    "    def __init__(self, root):\n",
    "        self.pics = glob.glob(f\"{root}/*.JPEG\")\n",
    "        self.tf = transforms.Compose([\n",
    "            transforms.Resize(pic_size),\n",
    "            transforms.CenterCrop(pic_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "        ])\n",
    "    def __len__(self): return len(self.pics)\n",
    "    def __getitem__(self, i):\n",
    "        img = Image.open(self.pics[i]).convert('RGB')\n",
    "        return self.tf(img)\n",
    "\n",
    "train_full = StyleDataset(\"data/train\")\n",
    "train_subset_len = 20000                     \n",
    "train_ds, _ = random_split(train_full, [train_subset_len, len(train_full)-train_subset_len])\n",
    "\n",
    "val_full = StyleDataset(\"data/val\")\n",
    "val_subset_len = 1000                     \n",
    "val_ds, _ = random_split(val_full, [val_subset_len, len(val_full)-val_subset_len])\n",
    "\n",
    "\n",
    "TrainLoader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "ValidateLoader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b563bb",
   "metadata": {},
   "source": [
    "读取必要参数后开始首先建立一个数据集类，实现__len__和__getitem__就可以了，后者要做一个转化。\n",
    "然后由于卡的性能不足，我裁切了一个子集来训练，这里指定了子集的大小，后序可能放到参数文件中\n",
    "然后建立数据集加载器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c6df9",
   "metadata": {},
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0143fb",
   "metadata": {},
   "source": [
    "## rtst.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f08b320",
   "metadata": {},
   "source": [
    "这里我网络的实现开始有一点错误，即上采样的时候函数不是原地修改，需要赋值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab2668",
   "metadata": {},
   "source": [
    "# src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2293bfdb",
   "metadata": {},
   "source": [
    "## fe_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fec6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.cfg import cfg\n",
    "from torchvision.models import vgg19\n",
    "from utils.cfg import cfg\n",
    "#feature extracting model\n",
    "fe_model = vgg19(weights=\"IMAGENET1K_V1\").features.eval().to(device=cfg['device'])\n",
    "for param in fe_model.parameters():\n",
    "    param.requires_grad=False\n",
    "\n",
    "from torchvision.models.feature_extraction import create_feature_extractor \n",
    "device = cfg['device']\n",
    "\n",
    "\n",
    "content_layers = cfg['content_layers']\n",
    "style_layers = cfg['style_layers']\n",
    "extractor = create_feature_extractor(fe_model, return_nodes={**{l: l for l in content_layers}, **{l: l for l in style_layers}}).to(device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3900439f",
   "metadata": {},
   "source": [
    "准备FE提取特征，提取出的内容是一个字典，键是层数，内容是张量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be343f4",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8105ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from fe_model import extractor\n",
    "from data.StyleDataset import TrainLoader, ValidateLoader\n",
    "from models.rtst import TransformerNet\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import TotalVariation\n",
    "from utils.log import log_info\n",
    "from utils.cfg import cfg\n",
    "from utils.weights import load_model, save_model\n",
    "from utils.gram import gram_matrix\n",
    "from utils.save import save_pics\n",
    "import logging\n",
    "\n",
    "RTST = TransformerNet()\n",
    "device = cfg['device']\n",
    "epochs = int(cfg['epochs'])\n",
    "style_pic = cfg['style_pic']\n",
    "freq = int(cfg['freq'])\n",
    "\n",
    "a = float(cfg['a'])\n",
    "b = float(cfg['b'])\n",
    "c = float(cfg['c'])\n",
    "\n",
    "content_layers = cfg['content_layers']\n",
    "style_layers = cfg['style_layers']\n",
    "\n",
    "\n",
    "lr = float(cfg['lr'])\n",
    "optimizer = Adam(params=RTST.parameters(), lr=lr)\n",
    "loss_func = F.mse_loss\n",
    "loss_tv = TotalVariation(reduction='sum').to(device=device) # Total Variation Loss\n",
    "pic_num = 0\n",
    "\n",
    "def train(\n",
    "    RTST: nn.Module,\n",
    "    FE:nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_fn,\n",
    "    loss_tv,\n",
    "    device: torch.device,\n",
    "    content_layers,\n",
    "    style_layers,\n",
    "    style_pic,\n",
    "    epochs: int,\n",
    "    scheduler,\n",
    "    log_fn,\n",
    "    a,\n",
    "    b,\n",
    "    c,\n",
    "    freq):\n",
    "    RTST.to(device)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        RTST.train()\n",
    "        for step, batch in enumerate(tqdm(train_loader)):\n",
    "            inputs = batch.to(device)\n",
    "            LT = 0 \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = RTST(inputs)\n",
    "            pic_save = outputs.clone()\n",
    "            Ltv = loss_tv(outputs) # Total Variation Loss\n",
    "\n",
    "            with torch.no_grad():\n",
    "                targets = FE(inputs)\n",
    "                outputs = FE(outputs)\n",
    "                styles = FE(style_pic)\n",
    "            Lc = 0 # Content Loss\n",
    "            for layer in content_layers:\n",
    "                Lc += loss_fn(outputs[layer], targets[layer])\n",
    "            Ls = 0 # Style Loss\n",
    "            for layer in style_layers:\n",
    "                Ls += loss_fn(gram_matrix(outputs[layer]), gram_matrix(styles[layer]))\n",
    "            LT = a*Lc + b*Ls + c*Ltv # Total Loss\n",
    "            if step % freq == 0:\n",
    "                log_fn(epoch=step, loss=LT, mode='train', place='step')\n",
    "                global pic_num \n",
    "                save_pics(inputs, pic_num)\n",
    "                n = save_pics(pic_save, pic_num)\n",
    "                pic_num += n\n",
    "\n",
    "            LT.backward()\n",
    "            optimizer.step()\n",
    "        if scheduler: \n",
    "            scheduler.step()\n",
    "        log_fn(epoch=epoch, loss=LT, mode='train', place='epoch')\n",
    "\n",
    "        if val_loader:\n",
    "            RTST.eval()\n",
    "            with torch.no_grad():\n",
    "                total_loss = 0\n",
    "                for batch in tqdm(val_loader):\n",
    "                    \n",
    "                    inputs = batch.to(device)\n",
    "                    LT = 0 \n",
    "\n",
    "                    outputs = RTST(inputs)\n",
    "                    Ltv = loss_tv(outputs) # Total Variation Loss\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        targets = FE(inputs)\n",
    "                        outputs = FE(outputs)\n",
    "                        styles = FE(style_pic)\n",
    "                    Lc = 0 # Content Loss\n",
    "                    for layer in content_layers:\n",
    "                        Lc += loss_fn(outputs[layer], targets[layer])\n",
    "                    Ls = 0 # Style Loss\n",
    "                    for layer in style_layers:\n",
    "                        Ls += loss_fn(gram_matrix(outputs[layer]), gram_matrix(styles[layer]))\n",
    "                    LT = a*Lc + b*Ls + c*Ltv # Total Loss\n",
    "\n",
    "                    total_loss += LT\n",
    "                log_fn(epoch=epoch, loss=LT/len(val_loader), mode='val', place='epoch')\n",
    "\n",
    "load = int(cfg['load'])\n",
    "save = int(cfg['save'])\n",
    "#load_model(RTST, load)\n",
    "train(RTST=RTST, FE=extractor, train_loader=TrainLoader, val_loader=ValidateLoader, optimizer=optimizer, loss_fn=loss_func, loss_tv=loss_tv, device=device,\n",
    "      content_layers=content_layers, style_layers=style_layers, style_pic=style_pic, epochs=epochs, log_fn=log_info, a=a, b=b, c=c,scheduler=None, freq=freq)\n",
    "save_model(RTST, save)\n",
    "                \n",
    "logging.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8be3842",
   "metadata": {},
   "source": [
    "首先导入工具，数据加载器，特征提取器，网络，优化器，日志，参数，图片保存可视化，损失函数。\n",
    "训练过程是将输入给网络得到输出，然后将输出和输入以及风格图片都提取特征，第一个和后两个计算损失，风格损失是多层次的，分别计算加，然后计算第一个的总体平滑损失，然后按照一定比例结合，最后优化。\n",
    "最后考虑权重的加载和存储。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b4e31c",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb934ebd",
   "metadata": {},
   "source": [
    "### cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161321aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "with open(\"configs/rtst.yaml\",\"r\",encoding='utf-8') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cfg['device'] = device\n",
    "style_pic = cfg['style_pic']\n",
    "style_pic = Image.open(style_pic).convert('RGB')\n",
    "mean = cfg['mean']\n",
    "std = cfg['std']\n",
    "pic_size = int(cfg['pic_size'])\n",
    "style_pic = transforms.Compose([\n",
    "            transforms.Resize(pic_size),\n",
    "            transforms.CenterCrop(pic_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "        ])(style_pic)\n",
    "\n",
    "cfg['style_pic'] = style_pic.unsqueeze(0).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80d74d3",
   "metadata": {},
   "source": [
    "这个文件的作用是从参数文件中读取数据，放在cfg中，供其他文件读取。\n",
    "同时这里我需要放置一些其他我想要的参数，比如设备，风格图片张量，因为这里的张量，后期日志的存储用yaml的函数有问题，使用pprint。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13af4297",
   "metadata": {},
   "source": [
    "### log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65fa9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import yaml\n",
    "from src.utils.cfg import cfg\n",
    "from logging.handlers import RotatingFileHandler\n",
    "from src.utils.tensorboard import writer\n",
    "from pprint import pformat\n",
    "\n",
    "experiment = cfg['experiment']\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "# 文件最大 10MB，保留 5 个备份\n",
    "handler = RotatingFileHandler(f'logs/experiment{experiment}.log', maxBytes=10*1024*1024, backupCount=5)\n",
    "logger.addHandler(handler)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "logger.info(\"current configuration\\n%s\", pformat(cfg))\n",
    "logger.info('start training')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def log_info(epoch, loss, mode, place):\n",
    "    info = f\"mode: {mode}\\n{place}: {epoch}\\nloss: {loss}\\n\\n\"\n",
    "    #print(info)\n",
    "    logger.info(info)\n",
    "    if mode == \"train\":\n",
    "        writer.add_scalar(f'{place}/train/loss', loss, epoch)\n",
    "    elif mode == \"val\":\n",
    "        writer.add_scalar(f'{place}/val/loss', loss, epoch)\n",
    "    else:\n",
    "        error_info = \"writer mode error!!!\"\n",
    "        #print(error_info)\n",
    "        logger.error(error_info)\n",
    "    writer.close()\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e4f370",
   "metadata": {},
   "source": [
    "这里在开始将参数配置加入日志，这里的配置是同名文件有5个，超过内容会循环覆盖。\n",
    "然后是一个函数用以记录数据，包括Tensorboard和log，log会同时打印。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed39175b",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5084a8ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“cv (Python 3.9.18)”的单元格需要ipykernel包。\n",
      "\u001b[1;31m使用所需的包 <a href='command:jupyter.createPythonEnvAndSelectController'>创建 Python 环境</a>。\n",
      "\u001b[1;31m或使用命令“conda install -n cv ipykernel --update-deps --force-reinstall”安装“ipykernel”"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "def save_pic(target, i):\n",
    "  denormalization = transforms.Normalize((-2.12, -2.04, -1.80), (4.37, 4.46, 4.44))\n",
    "  img = target.clone().squeeze()\n",
    "  img = denormalization(img).clamp(0, 1)\n",
    "#设定保存的路径和文件名\n",
    "  save_image(img, f'results/store/origin_{i}.png')\n",
    "  save_image(img, f'results/store/generate_{i}.png')\n",
    "\n",
    "def save_pics(target, i):\n",
    "  n, _, _, _ = target.shape\n",
    "  for j in range(n):\n",
    "    save_pic(target[j:j+1], i+j)\n",
    "  return n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e00961d",
   "metadata": {},
   "source": [
    "保存图片查看效果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc787e2d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
